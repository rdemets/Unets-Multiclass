<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.1" />
<title>models.CNN_Base API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>models.CNN_Base</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import os

import glob
import datetime

import skimage.io
import numpy as np

import tensorflow as tf

import keras
from keras import backend as K
from keras.models import Model, load_model
from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard, ProgbarLogger

from .internals.image_functions import Image_Functions
from .internals.network_config import Network_Config
from .internals.dataset import Dataset

class CNN_Base(Dataset, Image_Functions):
    def __init__(self, model_dir = None, config_filepath = None, **kwargs):
        &#34;&#34;&#34;Creates the base neural network class with basic functions
    
        Parameters
        ----------
        model_dir : `str`, optional
            [Default: None] Folder where the model is stored
        config_filepath : `str`, optional
            [Default: None] Filepath to the config file
        **kwargs
            Parameters that are passed to :class:`network_config.Network_Config`

        Attributes
        ----------
        config : :class:`network_config.Network_Config`
            Network_config object containing the config and necessary functions
        &#34;&#34;&#34;
        
        super().__init__()
        
        self.config = Network_Config(model_dir = model_dir, config_filepath = config_filepath, **kwargs)
        
        self.config.update_parameter([&#34;general&#34;, &#34;now&#34;], datetime.datetime.now())
        
        if self.config.get_parameter(&#34;use_cpu&#34;) is True:
            self.initialize_cpu()
        else:
            self.initialize_gpu()
    
    #######################
    # Logging functions
    #######################
    def init_logs(self):
        &#34;&#34;&#34;Initiates the parameters required for the log file
        &#34;&#34;&#34;
        # Directory for training logs
        print(self.config.get_parameter(&#34;name&#34;), self.config.get_parameter(&#34;now&#34;))
        self.log_dir = os.path.join(self.config.get_parameter(&#34;model_dir&#34;), &#34;{}-{:%Y%m%dT%H%M}&#34;.format(self.config.get_parameter(&#34;name&#34;), self.config.get_parameter(&#34;now&#34;)))
        
        # Path to save after each epoch. Include placeholders that get filled by Keras.
        self.checkpoint_path = os.path.join(self.log_dir, &#34;{}-{:%Y%m%dT%H%M}_*epoch*.h5&#34;.format(self.config.get_parameter(&#34;name&#34;), self.config.get_parameter(&#34;now&#34;)))
        self.checkpoint_path = self.checkpoint_path.replace(&#34;*epoch*&#34;, &#34;{epoch:04d}&#34;)
        
    def write_logs(self):
        &#34;&#34;&#34;Writes the log file
        &#34;&#34;&#34;
        # Create log_dir if it does not exist
        if os.path.exists(self.log_dir) is False:
            os.makedirs(self.log_dir)
            
        # save the parameters used in current run to logs dir
        self.config.write_config(os.path.join(self.log_dir, &#34;{}-{:%Y%m%dT%H%M}-config.yml&#34;.format(self.config.get_parameter(&#34;name&#34;), self.config.get_parameter(&#34;now&#34;))))
        
    #######################
    # Initialization functions
    #######################
    def summary(self):
        &#34;&#34;&#34;Summary of the layers in the model
        &#34;&#34;&#34;
        self.model.summary()
        
    def compile_model(self, optimizer, loss):
        &#34;&#34;&#34;Compiles model
        
        Parameters
        ----------
        optimizer
            Gradient optimizer used in during the training of the network
        loss
            Loss function of the network
        &#34;&#34;&#34;
        self.model.compile(optimizer, loss = loss, metrics = self.config.get_parameter(&#34;metrics&#34;))

    def initialize_model(self):
        &#34;&#34;&#34;Initializes the logs, builds the model, and chooses the correct initialization function
        &#34;&#34;&#34;
        # write parameters to yaml file
        self.init_logs()
        if self.config.get_parameter(&#34;for_prediction&#34;) is False:
            self.write_logs()
            
        # build model
        self.model = self.build_model(self.config.get_parameter(&#34;input_size&#34;))
        
        # save model to yaml file
        if self.config.get_parameter(&#34;for_prediction&#34;) is False:
            self.config.write_model(self.model, os.path.join(self.log_dir, &#34;{}-{:%Y%m%dT%H%M}-model.yml&#34;.format(self.config.get_parameter(&#34;name&#34;), self.config.get_parameter(&#34;now&#34;))))

        print(&#34;{} using single GPU or CPU..&#34;.format(&#34;Predicting&#34; if self.config.get_parameter(&#34;for_prediction&#34;) else &#34;Training&#34;))
        self.initialize_model_normal()
            
    def initialize_cpu(self):
        &#34;&#34;&#34;Sets the session to only use the CPU
        &#34;&#34;&#34;
        config = tf.ConfigProto(
                        device_count = {&#39;CPU&#39; : 1,
                                        &#39;GPU&#39; : 0}
                       )
        session = tf.Session(config=config)
        K.set_session(session)   
        
    def initialize_gpu(self):
        &#34;&#34;&#34;Sets the seesion to use the gpu specified in config file
        &#34;&#34;&#34;
        os.environ[&#34;CUDA_DEVICE_ORDER&#34;]=&#34;PCI_BUS_ID&#34;   # see issue #152
        os.environ[&#39;CUDA_VISIBLE_DEVICES&#39;] = str(self.config.get_parameter(&#34;visible_gpu&#34;)) # needs to be a string
        
        config = tf.ConfigProto()
        config.gpu_options.allow_growth = True
        sess = tf.Session(config=config)
        K.tensorflow_backend.set_session(sess)
    
    def initialize_model_normal(self):
        &#34;&#34;&#34;Initializes the optimizer and any specified callback functions
        &#34;&#34;&#34;
        opt = self.optimizer_function()
        self.compile_model(optimizer = opt, loss = self.loss_function(self.config.get_parameter(&#34;loss&#34;)))
        
        if self.config.get_parameter(&#34;for_prediction&#34;) == False:
            self.callbacks = [self.model_checkpoint_call(verbose = True)]

            if self.config.get_parameter(&#34;use_tensorboard&#34;) is True:
                self.callbacks.append(self.tensorboard_call())
                
            if self.config.get_parameter(&#34;reduce_LR_on_plateau&#34;) is True:
                self.callbacks.append(ReduceLROnPlateau(monitor=self.config.get_parameter(&#34;reduce_LR_monitor&#34;),
                                                        factor = self.config.get_parameter(&#34;reduce_LR_factor&#34;),
                                                        patience = self.config.get_parameter(&#34;reduce_LR_patience&#34;),
                                                        min_lr = self.config.get_parameter(&#34;reduce_LR_min_lr&#34;),
                                                        verbose = True))
            
            if self.config.get_parameter(&#34;early_stopping&#34;) is True:
                self.callbacks.append(EarlyStopping(monitor=self.config.get_parameter(&#34;early_stopping_monitor&#34;),
                                                    patience = self.config.get_parameter(&#34;early_stopping_patience&#34;),
                                                    min_delta = self.config.get_parameter(&#34;early_stopping_min_delta&#34;),
                                                    verbose = True))
                
    #######################
    # Optimizer/Loss functions
    #######################         
    def optimizer_function(self, learning_rate = None):
        &#34;&#34;&#34;Initialize optimizer function
        
        Parameters
        ----------
        learning_rate : `int`
            Learning rate of the descent algorithm
            
        Returns
        ----------
        optimizer
            Function to call the optimizer
        &#34;&#34;&#34;
        if learning_rate is None:
            learning_rate = self.config.get_parameter(&#34;learning_rate&#34;)
        if self.config.get_parameter(&#34;optimizer_function&#34;) == &#39;sgd&#39;:
            return keras.optimizers.SGD(lr = learning_rate, 
                                        decay = self.config.get_parameter(&#34;decay&#34;), 
                                        momentum = self.config.get_parameter(&#34;momentum&#34;), 
                                        nesterov = self.config.get_parameter(&#34;nesterov&#34;))
        elif self.config.get_parameter(&#34;optimizer_function&#34;) == &#39;rmsprop&#39;:
            return keras.optimizers.RMSprop(lr = learning_rate, 
                                            decay = self.config.get_parameter(&#34;decay&#34;))
        elif self.config.get_parameter(&#34;optimizer_function&#34;) == &#39;adam&#39;:
            return keras.optimizers.Adam(lr = learning_rate, 
                                         decay = self.config.get_parameter(&#34;decay&#34;))
        
    def loss_function(self, loss):
        &#34;&#34;&#34;Initialize loss function
        
        Parameters
        ----------
        loss : `str`
            Name of the loss function
            
        Returns
        ----------
        loss
            Function to call loss function
        &#34;&#34;&#34;
        if loss == &#34;binary_crossentropy&#34;:
            print(&#34;Using binary crossentropy&#34;)
            return loss
        elif loss == &#34;jaccard_distance_loss&#34;:
            print(&#34;Using jaccard distance loss&#34;)
            from .internals.losses import jaccard_distance_loss
            return jaccard_distance_loss
        elif loss == &#34;lovasz_hinge&#34;:
            print(&#34;Using Lovasz-hinge loss&#34;)
            from .internals.losses import lovasz_loss
            return lovasz_loss
        elif loss == &#34;dice_loss&#34;:
            print(&#34;Using Dice loss&#34;)
            from .internals.losses import dice_coef_loss
            return dice_coef_loss
        elif loss == &#34;bce_dice_loss&#34;:
            print(&#34;Using 1 - Dice + BCE loss&#34;)
            from .internals.losses import bce_dice_loss
            return bce_dice_loss
        elif loss == &#34;ssim_loss&#34;:
            print(&#34;Using DSSIM loss&#34;)
            from .internals.losses import DSSIM_loss
            return DSSIM_loss
        elif loss == &#34;bce_ssim_loss&#34;:
            print(&#34;Using BCE + DSSIM loss&#34;)
            from .internals.losses import bce_ssim_loss
            return bce_ssim_loss
        elif loss == &#34;mean_squared_error&#34;:
            return keras.losses.mean_squared_error
        elif loss == &#34;mean_absolute_error&#34;:
            return keras.losses.mean_absolute_error
        elif loss == &#34;ssim_mae_loss&#34;:
            print(&#34;Using DSSIM + MAE loss&#34;)
            from .internals.losses import dssim_mae_loss
            return dssim_mae_loss
        else:
            print(&#34;Using {}&#34;.format(loss))
            return loss
        
    #######################
    # Callbacks
    #######################     
    def tensorboard_call(self):
        &#34;&#34;&#34;Initialize tensorboard call
        &#34;&#34;&#34;
        return TensorBoard(log_dir=self.log_dir, 
                           batch_size = self.config.get_parameter(&#34;batch_size_per_GPU&#34;), 
                           write_graph=self.config.get_parameter(&#34;write_graph&#34;),
                           write_images=self.config.get_parameter(&#34;write_images&#34;), 
                           write_grads=self.config.get_parameter(&#34;write_grads&#34;), 
                           update_freq=&#39;epoch&#39;, 
                           histogram_freq=self.config.get_parameter(&#34;histogram_freq&#34;))
    
    def model_checkpoint_call(self, verbose = 0):
        &#34;&#34;&#34;Initialize model checkpoint call
        &#34;&#34;&#34;
        return ModelCheckpoint(self.checkpoint_path, save_weights_only=True, verbose=verbose)
    
    #######################
    # Clear memory once training is done
    #######################
    def end_training(self):
        &#34;&#34;&#34;Deletes model and releases gpu memory held by tensorflow
        &#34;&#34;&#34;
        # del reference to model
        del self.model
        
        # clear memory
        tf.reset_default_graph()
        K.clear_session()
        
        # take hold of cuda device to shut it down
        from numba import cuda
        cuda.select_device(0)
        cuda.close()
    
    #######################
    # Train Model
    #######################
    def train_model(self, verbose = True):
        &#34;&#34;&#34;Trains model
        
        Parameters
        ----------
        verbose : `int`, optional
            [Default: True] Verbose output
        &#34;&#34;&#34;      
        history = self.model.fit(self.aug_images, self.aug_ground_truth, validation_split = self.config.get_parameter(&#34;val_split&#34;),
                                 batch_size = self.config.get_parameter(&#34;batch_size&#34;), epochs = self.config.get_parameter(&#34;num_epochs&#34;), shuffle = True,
                                 callbacks=self.callbacks, verbose=verbose)
        
        self.end_training()
        
    #######################
    # Predict using loaded model weights
    ####################### 
    # TODO: change to load model from yaml file
    def load_model(self, model_dir = None):
        &#34;&#34;&#34;Loads model from h5 file
        
        Parameters
        ----------
        model_dir : `str`, optional
            [Default: None] Directory containing the model file
        &#34;&#34;&#34;
        # TODO: rewrite to load model from yaml file
        if model_dir is None:
            model_dir = self.config.get_parameter(&#34;model_dir&#34;)
            
        if os.path.isdir(model_dir) is True:
            list_weights_files = glob.glob(os.path.join(model_dir,&#39;*.h5&#39;))
            list_weights_files.sort() # To ensure that [-1] gives the last file
            
            model_dir = os.path.join(model_dir,list_weights_files[-1])

        self.model.load_model(model_dir)
        print(&#34;Loaded model from: &#34; + model_dir)
        
    def load_weights(self, model_dir = None, weights_index = -1):
        &#34;&#34;&#34;Loads weights from h5 file
        
        Parameters
        ----------
        model_dir : `str`, optional
            [Default: None] Directory containing the weights file
        weights_index : `int`, optional
            [Default: -1] 
        &#34;&#34;&#34;
        if model_dir is None:
            model_dir = self.config.get_parameter(&#34;model_dir&#34;)
        
        if os.path.isdir(model_dir) is True:
            list_weights_files = glob.glob(os.path.join(model_dir,&#39;*.h5&#39;))
            list_weights_files.sort() # To ensure that [-1] gives the last file
            self.weights_path = list_weights_files[weights_index]
            model_dir = os.path.join(model_dir, self.weights_path)
        else:
            self.weights_path = model_dir
        
        self.model.load_weights(model_dir)
        print(&#34;Loaded weights from: &#34; + model_dir)
       
    def predict_images(self, image_dir):
        &#34;&#34;&#34;Perform prediction on images found in ``image_dir``
        
        Parameters
        ----------
        image_dir : `str`
            Directory containing the images to perform prediction on
            
        Returns
        ----------
        image : `array_like`
            Last image that prediction was perfromed on
        &#34;&#34;&#34;
        # load image list
        image_list = self.list_images(image_dir)
        
        for image_path in image_list:
            image = self.load_image(image_path = image_path)
            
            # percentile normalization
            if self.config.get_parameter(&#34;percentile_normalization&#34;):
                image, _, _ = self.percentile_normalization(image, in_bound = self.config.get_parameter(&#34;percentile&#34;))
            
            if self.config.get_parameter(&#34;tile_overlap_size&#34;) == [0,0]:
                padding = None
                if image.shape[0] &lt; self.config.get_parameter(&#34;tile_size&#34;)[0] or image.shape[1] &lt; self.config.get_parameter(&#34;tile_size&#34;)[1]:
                    image, padding = self.pad_image(image, image_size = self.config.get_parameter(&#34;tile_size&#34;))
                input_image = image[np.newaxis,:,:,np.newaxis]
                
                output_image = self.model.predict(input_image, verbose=1)
                
                if padding is not None: 
                    h, w = output_image.shape[1:3]
                    output_image = np.reshape(output_image, (h, w))
                    output_image = self.remove_pad_image(output_image, padding = padding)
            else:
                tile_image_list, num_rows, num_cols, padding = self.tile_image(image, self.config.get_parameter(&#34;tile_size&#34;), self.config.get_parameter(&#34;tile_overlap_size&#34;))
                
                pred_train_list = []
                for tile in tile_image_list:

                    # reshape image to correct dimensions for unet
                    h, w = tile.shape[:2]
                    
                    tile = np.reshape(tile, (1, h, w, 1))

                    pred_train_list.extend(self.model.predict(tile, verbose=1))

                output_image = self.untile_image(pred_train_list, self.config.get_parameter(&#34;tile_size&#34;), self.config.get_parameter(&#34;tile_overlap_size&#34;),
                                                 num_rows, num_cols, padding = padding)
            
            self.save_image(output_image, image_path)
            
        return output_image
    
    def save_image(self, image, image_path, subfolder = &#39;Masks&#39;, suffix = &#39;-preds&#39;):
        &#34;&#34;&#34;Saves image to image_path
        
        Final location of image is as follows:
          - image_path
              - subfolder
                 - model/weights file name
        
        Parameters
        ----------
        image : `array_like`
            Image to be saved
        image_path : `str`
            Location to save the image in
        subfolder : `str`
            [Default: &#39;Masks&#39;] Subfolder in which the image is to be saved in
        suffix : `str`
            [Default: &#39;-preds&#39;] Suffix to append to the filename of the predicted image
        &#34;&#34;&#34;
        image_dir = os.path.dirname(image_path)
        
        output_dir = os.path.join(image_dir, subfolder)
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            
        basename, _ = os.path.splitext(os.path.basename(self.weights_path))
        
        output_dir = os.path.join(output_dir, basename)
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            
        filename, _ = os.path.splitext(os.path.basename(image_path))
        output_path = os.path.join(output_dir, &#34;{}{}.tif&#34;.format(filename, suffix))
        
        skimage.io.imsave(output_path, image)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="models.CNN_Base.CNN_Base"><code class="flex name class">
<span>class <span class="ident">CNN_Base</span></span>
<span>(</span><span>model_dir=None, config_filepath=None, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>Creates the base neural network class with basic functions</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>model_dir</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>[Default: None] Folder where the model is stored</dd>
<dt><strong><code>config_filepath</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>[Default: None] Filepath to the config file</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Parameters that are passed to :class:<code>network_config.Network_Config</code></dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>config</code></strong> :&ensp;:<code>class</code>:<code>network_config.Network_Config</code></dt>
<dd>Network_config object containing the config and necessary functions</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CNN_Base(Dataset, Image_Functions):
    def __init__(self, model_dir = None, config_filepath = None, **kwargs):
        &#34;&#34;&#34;Creates the base neural network class with basic functions
    
        Parameters
        ----------
        model_dir : `str`, optional
            [Default: None] Folder where the model is stored
        config_filepath : `str`, optional
            [Default: None] Filepath to the config file
        **kwargs
            Parameters that are passed to :class:`network_config.Network_Config`

        Attributes
        ----------
        config : :class:`network_config.Network_Config`
            Network_config object containing the config and necessary functions
        &#34;&#34;&#34;
        
        super().__init__()
        
        self.config = Network_Config(model_dir = model_dir, config_filepath = config_filepath, **kwargs)
        
        self.config.update_parameter([&#34;general&#34;, &#34;now&#34;], datetime.datetime.now())
        
        if self.config.get_parameter(&#34;use_cpu&#34;) is True:
            self.initialize_cpu()
        else:
            self.initialize_gpu()
    
    #######################
    # Logging functions
    #######################
    def init_logs(self):
        &#34;&#34;&#34;Initiates the parameters required for the log file
        &#34;&#34;&#34;
        # Directory for training logs
        print(self.config.get_parameter(&#34;name&#34;), self.config.get_parameter(&#34;now&#34;))
        self.log_dir = os.path.join(self.config.get_parameter(&#34;model_dir&#34;), &#34;{}-{:%Y%m%dT%H%M}&#34;.format(self.config.get_parameter(&#34;name&#34;), self.config.get_parameter(&#34;now&#34;)))
        
        # Path to save after each epoch. Include placeholders that get filled by Keras.
        self.checkpoint_path = os.path.join(self.log_dir, &#34;{}-{:%Y%m%dT%H%M}_*epoch*.h5&#34;.format(self.config.get_parameter(&#34;name&#34;), self.config.get_parameter(&#34;now&#34;)))
        self.checkpoint_path = self.checkpoint_path.replace(&#34;*epoch*&#34;, &#34;{epoch:04d}&#34;)
        
    def write_logs(self):
        &#34;&#34;&#34;Writes the log file
        &#34;&#34;&#34;
        # Create log_dir if it does not exist
        if os.path.exists(self.log_dir) is False:
            os.makedirs(self.log_dir)
            
        # save the parameters used in current run to logs dir
        self.config.write_config(os.path.join(self.log_dir, &#34;{}-{:%Y%m%dT%H%M}-config.yml&#34;.format(self.config.get_parameter(&#34;name&#34;), self.config.get_parameter(&#34;now&#34;))))
        
    #######################
    # Initialization functions
    #######################
    def summary(self):
        &#34;&#34;&#34;Summary of the layers in the model
        &#34;&#34;&#34;
        self.model.summary()
        
    def compile_model(self, optimizer, loss):
        &#34;&#34;&#34;Compiles model
        
        Parameters
        ----------
        optimizer
            Gradient optimizer used in during the training of the network
        loss
            Loss function of the network
        &#34;&#34;&#34;
        self.model.compile(optimizer, loss = loss, metrics = self.config.get_parameter(&#34;metrics&#34;))

    def initialize_model(self):
        &#34;&#34;&#34;Initializes the logs, builds the model, and chooses the correct initialization function
        &#34;&#34;&#34;
        # write parameters to yaml file
        self.init_logs()
        if self.config.get_parameter(&#34;for_prediction&#34;) is False:
            self.write_logs()
            
        # build model
        self.model = self.build_model(self.config.get_parameter(&#34;input_size&#34;))
        
        # save model to yaml file
        if self.config.get_parameter(&#34;for_prediction&#34;) is False:
            self.config.write_model(self.model, os.path.join(self.log_dir, &#34;{}-{:%Y%m%dT%H%M}-model.yml&#34;.format(self.config.get_parameter(&#34;name&#34;), self.config.get_parameter(&#34;now&#34;))))

        print(&#34;{} using single GPU or CPU..&#34;.format(&#34;Predicting&#34; if self.config.get_parameter(&#34;for_prediction&#34;) else &#34;Training&#34;))
        self.initialize_model_normal()
            
    def initialize_cpu(self):
        &#34;&#34;&#34;Sets the session to only use the CPU
        &#34;&#34;&#34;
        config = tf.ConfigProto(
                        device_count = {&#39;CPU&#39; : 1,
                                        &#39;GPU&#39; : 0}
                       )
        session = tf.Session(config=config)
        K.set_session(session)   
        
    def initialize_gpu(self):
        &#34;&#34;&#34;Sets the seesion to use the gpu specified in config file
        &#34;&#34;&#34;
        os.environ[&#34;CUDA_DEVICE_ORDER&#34;]=&#34;PCI_BUS_ID&#34;   # see issue #152
        os.environ[&#39;CUDA_VISIBLE_DEVICES&#39;] = str(self.config.get_parameter(&#34;visible_gpu&#34;)) # needs to be a string
        
        config = tf.ConfigProto()
        config.gpu_options.allow_growth = True
        sess = tf.Session(config=config)
        K.tensorflow_backend.set_session(sess)
    
    def initialize_model_normal(self):
        &#34;&#34;&#34;Initializes the optimizer and any specified callback functions
        &#34;&#34;&#34;
        opt = self.optimizer_function()
        self.compile_model(optimizer = opt, loss = self.loss_function(self.config.get_parameter(&#34;loss&#34;)))
        
        if self.config.get_parameter(&#34;for_prediction&#34;) == False:
            self.callbacks = [self.model_checkpoint_call(verbose = True)]

            if self.config.get_parameter(&#34;use_tensorboard&#34;) is True:
                self.callbacks.append(self.tensorboard_call())
                
            if self.config.get_parameter(&#34;reduce_LR_on_plateau&#34;) is True:
                self.callbacks.append(ReduceLROnPlateau(monitor=self.config.get_parameter(&#34;reduce_LR_monitor&#34;),
                                                        factor = self.config.get_parameter(&#34;reduce_LR_factor&#34;),
                                                        patience = self.config.get_parameter(&#34;reduce_LR_patience&#34;),
                                                        min_lr = self.config.get_parameter(&#34;reduce_LR_min_lr&#34;),
                                                        verbose = True))
            
            if self.config.get_parameter(&#34;early_stopping&#34;) is True:
                self.callbacks.append(EarlyStopping(monitor=self.config.get_parameter(&#34;early_stopping_monitor&#34;),
                                                    patience = self.config.get_parameter(&#34;early_stopping_patience&#34;),
                                                    min_delta = self.config.get_parameter(&#34;early_stopping_min_delta&#34;),
                                                    verbose = True))
                
    #######################
    # Optimizer/Loss functions
    #######################         
    def optimizer_function(self, learning_rate = None):
        &#34;&#34;&#34;Initialize optimizer function
        
        Parameters
        ----------
        learning_rate : `int`
            Learning rate of the descent algorithm
            
        Returns
        ----------
        optimizer
            Function to call the optimizer
        &#34;&#34;&#34;
        if learning_rate is None:
            learning_rate = self.config.get_parameter(&#34;learning_rate&#34;)
        if self.config.get_parameter(&#34;optimizer_function&#34;) == &#39;sgd&#39;:
            return keras.optimizers.SGD(lr = learning_rate, 
                                        decay = self.config.get_parameter(&#34;decay&#34;), 
                                        momentum = self.config.get_parameter(&#34;momentum&#34;), 
                                        nesterov = self.config.get_parameter(&#34;nesterov&#34;))
        elif self.config.get_parameter(&#34;optimizer_function&#34;) == &#39;rmsprop&#39;:
            return keras.optimizers.RMSprop(lr = learning_rate, 
                                            decay = self.config.get_parameter(&#34;decay&#34;))
        elif self.config.get_parameter(&#34;optimizer_function&#34;) == &#39;adam&#39;:
            return keras.optimizers.Adam(lr = learning_rate, 
                                         decay = self.config.get_parameter(&#34;decay&#34;))
        
    def loss_function(self, loss):
        &#34;&#34;&#34;Initialize loss function
        
        Parameters
        ----------
        loss : `str`
            Name of the loss function
            
        Returns
        ----------
        loss
            Function to call loss function
        &#34;&#34;&#34;
        if loss == &#34;binary_crossentropy&#34;:
            print(&#34;Using binary crossentropy&#34;)
            return loss
        elif loss == &#34;jaccard_distance_loss&#34;:
            print(&#34;Using jaccard distance loss&#34;)
            from .internals.losses import jaccard_distance_loss
            return jaccard_distance_loss
        elif loss == &#34;lovasz_hinge&#34;:
            print(&#34;Using Lovasz-hinge loss&#34;)
            from .internals.losses import lovasz_loss
            return lovasz_loss
        elif loss == &#34;dice_loss&#34;:
            print(&#34;Using Dice loss&#34;)
            from .internals.losses import dice_coef_loss
            return dice_coef_loss
        elif loss == &#34;bce_dice_loss&#34;:
            print(&#34;Using 1 - Dice + BCE loss&#34;)
            from .internals.losses import bce_dice_loss
            return bce_dice_loss
        elif loss == &#34;ssim_loss&#34;:
            print(&#34;Using DSSIM loss&#34;)
            from .internals.losses import DSSIM_loss
            return DSSIM_loss
        elif loss == &#34;bce_ssim_loss&#34;:
            print(&#34;Using BCE + DSSIM loss&#34;)
            from .internals.losses import bce_ssim_loss
            return bce_ssim_loss
        elif loss == &#34;mean_squared_error&#34;:
            return keras.losses.mean_squared_error
        elif loss == &#34;mean_absolute_error&#34;:
            return keras.losses.mean_absolute_error
        elif loss == &#34;ssim_mae_loss&#34;:
            print(&#34;Using DSSIM + MAE loss&#34;)
            from .internals.losses import dssim_mae_loss
            return dssim_mae_loss
        else:
            print(&#34;Using {}&#34;.format(loss))
            return loss
        
    #######################
    # Callbacks
    #######################     
    def tensorboard_call(self):
        &#34;&#34;&#34;Initialize tensorboard call
        &#34;&#34;&#34;
        return TensorBoard(log_dir=self.log_dir, 
                           batch_size = self.config.get_parameter(&#34;batch_size_per_GPU&#34;), 
                           write_graph=self.config.get_parameter(&#34;write_graph&#34;),
                           write_images=self.config.get_parameter(&#34;write_images&#34;), 
                           write_grads=self.config.get_parameter(&#34;write_grads&#34;), 
                           update_freq=&#39;epoch&#39;, 
                           histogram_freq=self.config.get_parameter(&#34;histogram_freq&#34;))
    
    def model_checkpoint_call(self, verbose = 0):
        &#34;&#34;&#34;Initialize model checkpoint call
        &#34;&#34;&#34;
        return ModelCheckpoint(self.checkpoint_path, save_weights_only=True, verbose=verbose)
    
    #######################
    # Clear memory once training is done
    #######################
    def end_training(self):
        &#34;&#34;&#34;Deletes model and releases gpu memory held by tensorflow
        &#34;&#34;&#34;
        # del reference to model
        del self.model
        
        # clear memory
        tf.reset_default_graph()
        K.clear_session()
        
        # take hold of cuda device to shut it down
        from numba import cuda
        cuda.select_device(0)
        cuda.close()
    
    #######################
    # Train Model
    #######################
    def train_model(self, verbose = True):
        &#34;&#34;&#34;Trains model
        
        Parameters
        ----------
        verbose : `int`, optional
            [Default: True] Verbose output
        &#34;&#34;&#34;      
        history = self.model.fit(self.aug_images, self.aug_ground_truth, validation_split = self.config.get_parameter(&#34;val_split&#34;),
                                 batch_size = self.config.get_parameter(&#34;batch_size&#34;), epochs = self.config.get_parameter(&#34;num_epochs&#34;), shuffle = True,
                                 callbacks=self.callbacks, verbose=verbose)
        
        self.end_training()
        
    #######################
    # Predict using loaded model weights
    ####################### 
    # TODO: change to load model from yaml file
    def load_model(self, model_dir = None):
        &#34;&#34;&#34;Loads model from h5 file
        
        Parameters
        ----------
        model_dir : `str`, optional
            [Default: None] Directory containing the model file
        &#34;&#34;&#34;
        # TODO: rewrite to load model from yaml file
        if model_dir is None:
            model_dir = self.config.get_parameter(&#34;model_dir&#34;)
            
        if os.path.isdir(model_dir) is True:
            list_weights_files = glob.glob(os.path.join(model_dir,&#39;*.h5&#39;))
            list_weights_files.sort() # To ensure that [-1] gives the last file
            
            model_dir = os.path.join(model_dir,list_weights_files[-1])

        self.model.load_model(model_dir)
        print(&#34;Loaded model from: &#34; + model_dir)
        
    def load_weights(self, model_dir = None, weights_index = -1):
        &#34;&#34;&#34;Loads weights from h5 file
        
        Parameters
        ----------
        model_dir : `str`, optional
            [Default: None] Directory containing the weights file
        weights_index : `int`, optional
            [Default: -1] 
        &#34;&#34;&#34;
        if model_dir is None:
            model_dir = self.config.get_parameter(&#34;model_dir&#34;)
        
        if os.path.isdir(model_dir) is True:
            list_weights_files = glob.glob(os.path.join(model_dir,&#39;*.h5&#39;))
            list_weights_files.sort() # To ensure that [-1] gives the last file
            self.weights_path = list_weights_files[weights_index]
            model_dir = os.path.join(model_dir, self.weights_path)
        else:
            self.weights_path = model_dir
        
        self.model.load_weights(model_dir)
        print(&#34;Loaded weights from: &#34; + model_dir)
       
    def predict_images(self, image_dir):
        &#34;&#34;&#34;Perform prediction on images found in ``image_dir``
        
        Parameters
        ----------
        image_dir : `str`
            Directory containing the images to perform prediction on
            
        Returns
        ----------
        image : `array_like`
            Last image that prediction was perfromed on
        &#34;&#34;&#34;
        # load image list
        image_list = self.list_images(image_dir)
        
        for image_path in image_list:
            image = self.load_image(image_path = image_path)
            
            # percentile normalization
            if self.config.get_parameter(&#34;percentile_normalization&#34;):
                image, _, _ = self.percentile_normalization(image, in_bound = self.config.get_parameter(&#34;percentile&#34;))
            
            if self.config.get_parameter(&#34;tile_overlap_size&#34;) == [0,0]:
                padding = None
                if image.shape[0] &lt; self.config.get_parameter(&#34;tile_size&#34;)[0] or image.shape[1] &lt; self.config.get_parameter(&#34;tile_size&#34;)[1]:
                    image, padding = self.pad_image(image, image_size = self.config.get_parameter(&#34;tile_size&#34;))
                input_image = image[np.newaxis,:,:,np.newaxis]
                
                output_image = self.model.predict(input_image, verbose=1)
                
                if padding is not None: 
                    h, w = output_image.shape[1:3]
                    output_image = np.reshape(output_image, (h, w))
                    output_image = self.remove_pad_image(output_image, padding = padding)
            else:
                tile_image_list, num_rows, num_cols, padding = self.tile_image(image, self.config.get_parameter(&#34;tile_size&#34;), self.config.get_parameter(&#34;tile_overlap_size&#34;))
                
                pred_train_list = []
                for tile in tile_image_list:

                    # reshape image to correct dimensions for unet
                    h, w = tile.shape[:2]
                    
                    tile = np.reshape(tile, (1, h, w, 1))

                    pred_train_list.extend(self.model.predict(tile, verbose=1))

                output_image = self.untile_image(pred_train_list, self.config.get_parameter(&#34;tile_size&#34;), self.config.get_parameter(&#34;tile_overlap_size&#34;),
                                                 num_rows, num_cols, padding = padding)
            
            self.save_image(output_image, image_path)
            
        return output_image
    
    def save_image(self, image, image_path, subfolder = &#39;Masks&#39;, suffix = &#39;-preds&#39;):
        &#34;&#34;&#34;Saves image to image_path
        
        Final location of image is as follows:
          - image_path
              - subfolder
                 - model/weights file name
        
        Parameters
        ----------
        image : `array_like`
            Image to be saved
        image_path : `str`
            Location to save the image in
        subfolder : `str`
            [Default: &#39;Masks&#39;] Subfolder in which the image is to be saved in
        suffix : `str`
            [Default: &#39;-preds&#39;] Suffix to append to the filename of the predicted image
        &#34;&#34;&#34;
        image_dir = os.path.dirname(image_path)
        
        output_dir = os.path.join(image_dir, subfolder)
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            
        basename, _ = os.path.splitext(os.path.basename(self.weights_path))
        
        output_dir = os.path.join(output_dir, basename)
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            
        filename, _ = os.path.splitext(os.path.basename(image_path))
        output_path = os.path.join(output_dir, &#34;{}{}.tif&#34;.format(filename, suffix))
        
        skimage.io.imsave(output_path, image)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="models.internals.dataset.Dataset" href="internals/dataset.html#models.internals.dataset.Dataset">Dataset</a></li>
<li><a title="models.internals.image_functions.Image_Functions" href="internals/image_functions.html#models.internals.image_functions.Image_Functions">Image_Functions</a></li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="models.Unet.Unet" href="Unet.html#models.Unet.Unet">Unet</a></li>
<li><a title="models.Unet_Resnet.Unet_Resnet" href="Unet_Resnet.html#models.Unet_Resnet.Unet_Resnet">Unet_Resnet</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="models.CNN_Base.CNN_Base.compile_model"><code class="name flex">
<span>def <span class="ident">compile_model</span></span>(<span>self, optimizer, loss)</span>
</code></dt>
<dd>
<section class="desc"><p>Compiles model</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>optimizer</code></strong></dt>
<dd>Gradient optimizer used in during the training of the network</dd>
<dt><strong><code>loss</code></strong></dt>
<dd>Loss function of the network</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compile_model(self, optimizer, loss):
    &#34;&#34;&#34;Compiles model
    
    Parameters
    ----------
    optimizer
        Gradient optimizer used in during the training of the network
    loss
        Loss function of the network
    &#34;&#34;&#34;
    self.model.compile(optimizer, loss = loss, metrics = self.config.get_parameter(&#34;metrics&#34;))</code></pre>
</details>
</dd>
<dt id="models.CNN_Base.CNN_Base.end_training"><code class="name flex">
<span>def <span class="ident">end_training</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Deletes model and releases gpu memory held by tensorflow</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def end_training(self):
    &#34;&#34;&#34;Deletes model and releases gpu memory held by tensorflow
    &#34;&#34;&#34;
    # del reference to model
    del self.model
    
    # clear memory
    tf.reset_default_graph()
    K.clear_session()
    
    # take hold of cuda device to shut it down
    from numba import cuda
    cuda.select_device(0)
    cuda.close()</code></pre>
</details>
</dd>
<dt id="models.CNN_Base.CNN_Base.init_logs"><code class="name flex">
<span>def <span class="ident">init_logs</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Initiates the parameters required for the log file</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def init_logs(self):
    &#34;&#34;&#34;Initiates the parameters required for the log file
    &#34;&#34;&#34;
    # Directory for training logs
    print(self.config.get_parameter(&#34;name&#34;), self.config.get_parameter(&#34;now&#34;))
    self.log_dir = os.path.join(self.config.get_parameter(&#34;model_dir&#34;), &#34;{}-{:%Y%m%dT%H%M}&#34;.format(self.config.get_parameter(&#34;name&#34;), self.config.get_parameter(&#34;now&#34;)))
    
    # Path to save after each epoch. Include placeholders that get filled by Keras.
    self.checkpoint_path = os.path.join(self.log_dir, &#34;{}-{:%Y%m%dT%H%M}_*epoch*.h5&#34;.format(self.config.get_parameter(&#34;name&#34;), self.config.get_parameter(&#34;now&#34;)))
    self.checkpoint_path = self.checkpoint_path.replace(&#34;*epoch*&#34;, &#34;{epoch:04d}&#34;)</code></pre>
</details>
</dd>
<dt id="models.CNN_Base.CNN_Base.initialize_cpu"><code class="name flex">
<span>def <span class="ident">initialize_cpu</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Sets the session to only use the CPU</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def initialize_cpu(self):
    &#34;&#34;&#34;Sets the session to only use the CPU
    &#34;&#34;&#34;
    config = tf.ConfigProto(
                    device_count = {&#39;CPU&#39; : 1,
                                    &#39;GPU&#39; : 0}
                   )
    session = tf.Session(config=config)
    K.set_session(session)   </code></pre>
</details>
</dd>
<dt id="models.CNN_Base.CNN_Base.initialize_gpu"><code class="name flex">
<span>def <span class="ident">initialize_gpu</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Sets the seesion to use the gpu specified in config file</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def initialize_gpu(self):
    &#34;&#34;&#34;Sets the seesion to use the gpu specified in config file
    &#34;&#34;&#34;
    os.environ[&#34;CUDA_DEVICE_ORDER&#34;]=&#34;PCI_BUS_ID&#34;   # see issue #152
    os.environ[&#39;CUDA_VISIBLE_DEVICES&#39;] = str(self.config.get_parameter(&#34;visible_gpu&#34;)) # needs to be a string
    
    config = tf.ConfigProto()
    config.gpu_options.allow_growth = True
    sess = tf.Session(config=config)
    K.tensorflow_backend.set_session(sess)</code></pre>
</details>
</dd>
<dt id="models.CNN_Base.CNN_Base.initialize_model"><code class="name flex">
<span>def <span class="ident">initialize_model</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Initializes the logs, builds the model, and chooses the correct initialization function</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def initialize_model(self):
    &#34;&#34;&#34;Initializes the logs, builds the model, and chooses the correct initialization function
    &#34;&#34;&#34;
    # write parameters to yaml file
    self.init_logs()
    if self.config.get_parameter(&#34;for_prediction&#34;) is False:
        self.write_logs()
        
    # build model
    self.model = self.build_model(self.config.get_parameter(&#34;input_size&#34;))
    
    # save model to yaml file
    if self.config.get_parameter(&#34;for_prediction&#34;) is False:
        self.config.write_model(self.model, os.path.join(self.log_dir, &#34;{}-{:%Y%m%dT%H%M}-model.yml&#34;.format(self.config.get_parameter(&#34;name&#34;), self.config.get_parameter(&#34;now&#34;))))

    print(&#34;{} using single GPU or CPU..&#34;.format(&#34;Predicting&#34; if self.config.get_parameter(&#34;for_prediction&#34;) else &#34;Training&#34;))
    self.initialize_model_normal()</code></pre>
</details>
</dd>
<dt id="models.CNN_Base.CNN_Base.initialize_model_normal"><code class="name flex">
<span>def <span class="ident">initialize_model_normal</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Initializes the optimizer and any specified callback functions</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def initialize_model_normal(self):
    &#34;&#34;&#34;Initializes the optimizer and any specified callback functions
    &#34;&#34;&#34;
    opt = self.optimizer_function()
    self.compile_model(optimizer = opt, loss = self.loss_function(self.config.get_parameter(&#34;loss&#34;)))
    
    if self.config.get_parameter(&#34;for_prediction&#34;) == False:
        self.callbacks = [self.model_checkpoint_call(verbose = True)]

        if self.config.get_parameter(&#34;use_tensorboard&#34;) is True:
            self.callbacks.append(self.tensorboard_call())
            
        if self.config.get_parameter(&#34;reduce_LR_on_plateau&#34;) is True:
            self.callbacks.append(ReduceLROnPlateau(monitor=self.config.get_parameter(&#34;reduce_LR_monitor&#34;),
                                                    factor = self.config.get_parameter(&#34;reduce_LR_factor&#34;),
                                                    patience = self.config.get_parameter(&#34;reduce_LR_patience&#34;),
                                                    min_lr = self.config.get_parameter(&#34;reduce_LR_min_lr&#34;),
                                                    verbose = True))
        
        if self.config.get_parameter(&#34;early_stopping&#34;) is True:
            self.callbacks.append(EarlyStopping(monitor=self.config.get_parameter(&#34;early_stopping_monitor&#34;),
                                                patience = self.config.get_parameter(&#34;early_stopping_patience&#34;),
                                                min_delta = self.config.get_parameter(&#34;early_stopping_min_delta&#34;),
                                                verbose = True))</code></pre>
</details>
</dd>
<dt id="models.CNN_Base.CNN_Base.load_model"><code class="name flex">
<span>def <span class="ident">load_model</span></span>(<span>self, model_dir=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Loads model from h5 file</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>model_dir</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>[Default: None] Directory containing the model file</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_model(self, model_dir = None):
    &#34;&#34;&#34;Loads model from h5 file
    
    Parameters
    ----------
    model_dir : `str`, optional
        [Default: None] Directory containing the model file
    &#34;&#34;&#34;
    # TODO: rewrite to load model from yaml file
    if model_dir is None:
        model_dir = self.config.get_parameter(&#34;model_dir&#34;)
        
    if os.path.isdir(model_dir) is True:
        list_weights_files = glob.glob(os.path.join(model_dir,&#39;*.h5&#39;))
        list_weights_files.sort() # To ensure that [-1] gives the last file
        
        model_dir = os.path.join(model_dir,list_weights_files[-1])

    self.model.load_model(model_dir)
    print(&#34;Loaded model from: &#34; + model_dir)</code></pre>
</details>
</dd>
<dt id="models.CNN_Base.CNN_Base.load_weights"><code class="name flex">
<span>def <span class="ident">load_weights</span></span>(<span>self, model_dir=None, weights_index=-1)</span>
</code></dt>
<dd>
<section class="desc"><p>Loads weights from h5 file</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>model_dir</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>[Default: None] Directory containing the weights file</dd>
<dt><strong><code>weights_index</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>[Default: -1]</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_weights(self, model_dir = None, weights_index = -1):
    &#34;&#34;&#34;Loads weights from h5 file
    
    Parameters
    ----------
    model_dir : `str`, optional
        [Default: None] Directory containing the weights file
    weights_index : `int`, optional
        [Default: -1] 
    &#34;&#34;&#34;
    if model_dir is None:
        model_dir = self.config.get_parameter(&#34;model_dir&#34;)
    
    if os.path.isdir(model_dir) is True:
        list_weights_files = glob.glob(os.path.join(model_dir,&#39;*.h5&#39;))
        list_weights_files.sort() # To ensure that [-1] gives the last file
        self.weights_path = list_weights_files[weights_index]
        model_dir = os.path.join(model_dir, self.weights_path)
    else:
        self.weights_path = model_dir
    
    self.model.load_weights(model_dir)
    print(&#34;Loaded weights from: &#34; + model_dir)</code></pre>
</details>
</dd>
<dt id="models.CNN_Base.CNN_Base.loss_function"><code class="name flex">
<span>def <span class="ident">loss_function</span></span>(<span>self, loss)</span>
</code></dt>
<dd>
<section class="desc"><p>Initialize loss function</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>loss</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the loss function</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>loss</code></dt>
<dd>Function to call loss function</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def loss_function(self, loss):
    &#34;&#34;&#34;Initialize loss function
    
    Parameters
    ----------
    loss : `str`
        Name of the loss function
        
    Returns
    ----------
    loss
        Function to call loss function
    &#34;&#34;&#34;
    if loss == &#34;binary_crossentropy&#34;:
        print(&#34;Using binary crossentropy&#34;)
        return loss
    elif loss == &#34;jaccard_distance_loss&#34;:
        print(&#34;Using jaccard distance loss&#34;)
        from .internals.losses import jaccard_distance_loss
        return jaccard_distance_loss
    elif loss == &#34;lovasz_hinge&#34;:
        print(&#34;Using Lovasz-hinge loss&#34;)
        from .internals.losses import lovasz_loss
        return lovasz_loss
    elif loss == &#34;dice_loss&#34;:
        print(&#34;Using Dice loss&#34;)
        from .internals.losses import dice_coef_loss
        return dice_coef_loss
    elif loss == &#34;bce_dice_loss&#34;:
        print(&#34;Using 1 - Dice + BCE loss&#34;)
        from .internals.losses import bce_dice_loss
        return bce_dice_loss
    elif loss == &#34;ssim_loss&#34;:
        print(&#34;Using DSSIM loss&#34;)
        from .internals.losses import DSSIM_loss
        return DSSIM_loss
    elif loss == &#34;bce_ssim_loss&#34;:
        print(&#34;Using BCE + DSSIM loss&#34;)
        from .internals.losses import bce_ssim_loss
        return bce_ssim_loss
    elif loss == &#34;mean_squared_error&#34;:
        return keras.losses.mean_squared_error
    elif loss == &#34;mean_absolute_error&#34;:
        return keras.losses.mean_absolute_error
    elif loss == &#34;ssim_mae_loss&#34;:
        print(&#34;Using DSSIM + MAE loss&#34;)
        from .internals.losses import dssim_mae_loss
        return dssim_mae_loss
    else:
        print(&#34;Using {}&#34;.format(loss))
        return loss</code></pre>
</details>
</dd>
<dt id="models.CNN_Base.CNN_Base.model_checkpoint_call"><code class="name flex">
<span>def <span class="ident">model_checkpoint_call</span></span>(<span>self, verbose=0)</span>
</code></dt>
<dd>
<section class="desc"><p>Initialize model checkpoint call</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def model_checkpoint_call(self, verbose = 0):
    &#34;&#34;&#34;Initialize model checkpoint call
    &#34;&#34;&#34;
    return ModelCheckpoint(self.checkpoint_path, save_weights_only=True, verbose=verbose)</code></pre>
</details>
</dd>
<dt id="models.CNN_Base.CNN_Base.optimizer_function"><code class="name flex">
<span>def <span class="ident">optimizer_function</span></span>(<span>self, learning_rate=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Initialize optimizer function</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>learning_rate</code></strong> :&ensp;<code>int</code></dt>
<dd>Learning rate of the descent algorithm</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>optimizer</code></dt>
<dd>Function to call the optimizer</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def optimizer_function(self, learning_rate = None):
    &#34;&#34;&#34;Initialize optimizer function
    
    Parameters
    ----------
    learning_rate : `int`
        Learning rate of the descent algorithm
        
    Returns
    ----------
    optimizer
        Function to call the optimizer
    &#34;&#34;&#34;
    if learning_rate is None:
        learning_rate = self.config.get_parameter(&#34;learning_rate&#34;)
    if self.config.get_parameter(&#34;optimizer_function&#34;) == &#39;sgd&#39;:
        return keras.optimizers.SGD(lr = learning_rate, 
                                    decay = self.config.get_parameter(&#34;decay&#34;), 
                                    momentum = self.config.get_parameter(&#34;momentum&#34;), 
                                    nesterov = self.config.get_parameter(&#34;nesterov&#34;))
    elif self.config.get_parameter(&#34;optimizer_function&#34;) == &#39;rmsprop&#39;:
        return keras.optimizers.RMSprop(lr = learning_rate, 
                                        decay = self.config.get_parameter(&#34;decay&#34;))
    elif self.config.get_parameter(&#34;optimizer_function&#34;) == &#39;adam&#39;:
        return keras.optimizers.Adam(lr = learning_rate, 
                                     decay = self.config.get_parameter(&#34;decay&#34;))</code></pre>
</details>
</dd>
<dt id="models.CNN_Base.CNN_Base.predict_images"><code class="name flex">
<span>def <span class="ident">predict_images</span></span>(<span>self, image_dir)</span>
</code></dt>
<dd>
<section class="desc"><p>Perform prediction on images found in <code>image_dir</code></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>image_dir</code></strong> :&ensp;<code>str</code></dt>
<dd>Directory containing the images to perform prediction on</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>array_like</code></dt>
<dd>Last image that prediction was perfromed on</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict_images(self, image_dir):
    &#34;&#34;&#34;Perform prediction on images found in ``image_dir``
    
    Parameters
    ----------
    image_dir : `str`
        Directory containing the images to perform prediction on
        
    Returns
    ----------
    image : `array_like`
        Last image that prediction was perfromed on
    &#34;&#34;&#34;
    # load image list
    image_list = self.list_images(image_dir)
    
    for image_path in image_list:
        image = self.load_image(image_path = image_path)
        
        # percentile normalization
        if self.config.get_parameter(&#34;percentile_normalization&#34;):
            image, _, _ = self.percentile_normalization(image, in_bound = self.config.get_parameter(&#34;percentile&#34;))
        
        if self.config.get_parameter(&#34;tile_overlap_size&#34;) == [0,0]:
            padding = None
            if image.shape[0] &lt; self.config.get_parameter(&#34;tile_size&#34;)[0] or image.shape[1] &lt; self.config.get_parameter(&#34;tile_size&#34;)[1]:
                image, padding = self.pad_image(image, image_size = self.config.get_parameter(&#34;tile_size&#34;))
            input_image = image[np.newaxis,:,:,np.newaxis]
            
            output_image = self.model.predict(input_image, verbose=1)
            
            if padding is not None: 
                h, w = output_image.shape[1:3]
                output_image = np.reshape(output_image, (h, w))
                output_image = self.remove_pad_image(output_image, padding = padding)
        else:
            tile_image_list, num_rows, num_cols, padding = self.tile_image(image, self.config.get_parameter(&#34;tile_size&#34;), self.config.get_parameter(&#34;tile_overlap_size&#34;))
            
            pred_train_list = []
            for tile in tile_image_list:

                # reshape image to correct dimensions for unet
                h, w = tile.shape[:2]
                
                tile = np.reshape(tile, (1, h, w, 1))

                pred_train_list.extend(self.model.predict(tile, verbose=1))

            output_image = self.untile_image(pred_train_list, self.config.get_parameter(&#34;tile_size&#34;), self.config.get_parameter(&#34;tile_overlap_size&#34;),
                                             num_rows, num_cols, padding = padding)
        
        self.save_image(output_image, image_path)
        
    return output_image</code></pre>
</details>
</dd>
<dt id="models.CNN_Base.CNN_Base.save_image"><code class="name flex">
<span>def <span class="ident">save_image</span></span>(<span>self, image, image_path, subfolder='Masks', suffix='-preds')</span>
</code></dt>
<dd>
<section class="desc"><p>Saves image to image_path</p>
<p>Final location of image is as follows:
- image_path
- subfolder
- model/weights file name</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>array_like</code></dt>
<dd>Image to be saved</dd>
<dt><strong><code>image_path</code></strong> :&ensp;<code>str</code></dt>
<dd>Location to save the image in</dd>
<dt><strong><code>subfolder</code></strong> :&ensp;<code>str</code></dt>
<dd>[Default: 'Masks'] Subfolder in which the image is to be saved in</dd>
<dt><strong><code>suffix</code></strong> :&ensp;<code>str</code></dt>
<dd>[Default: '-preds'] Suffix to append to the filename of the predicted image</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_image(self, image, image_path, subfolder = &#39;Masks&#39;, suffix = &#39;-preds&#39;):
    &#34;&#34;&#34;Saves image to image_path
    
    Final location of image is as follows:
      - image_path
          - subfolder
             - model/weights file name
    
    Parameters
    ----------
    image : `array_like`
        Image to be saved
    image_path : `str`
        Location to save the image in
    subfolder : `str`
        [Default: &#39;Masks&#39;] Subfolder in which the image is to be saved in
    suffix : `str`
        [Default: &#39;-preds&#39;] Suffix to append to the filename of the predicted image
    &#34;&#34;&#34;
    image_dir = os.path.dirname(image_path)
    
    output_dir = os.path.join(image_dir, subfolder)
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        
    basename, _ = os.path.splitext(os.path.basename(self.weights_path))
    
    output_dir = os.path.join(output_dir, basename)
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        
    filename, _ = os.path.splitext(os.path.basename(image_path))
    output_path = os.path.join(output_dir, &#34;{}{}.tif&#34;.format(filename, suffix))
    
    skimage.io.imsave(output_path, image)</code></pre>
</details>
</dd>
<dt id="models.CNN_Base.CNN_Base.summary"><code class="name flex">
<span>def <span class="ident">summary</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Summary of the layers in the model</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def summary(self):
    &#34;&#34;&#34;Summary of the layers in the model
    &#34;&#34;&#34;
    self.model.summary()</code></pre>
</details>
</dd>
<dt id="models.CNN_Base.CNN_Base.tensorboard_call"><code class="name flex">
<span>def <span class="ident">tensorboard_call</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Initialize tensorboard call</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tensorboard_call(self):
    &#34;&#34;&#34;Initialize tensorboard call
    &#34;&#34;&#34;
    return TensorBoard(log_dir=self.log_dir, 
                       batch_size = self.config.get_parameter(&#34;batch_size_per_GPU&#34;), 
                       write_graph=self.config.get_parameter(&#34;write_graph&#34;),
                       write_images=self.config.get_parameter(&#34;write_images&#34;), 
                       write_grads=self.config.get_parameter(&#34;write_grads&#34;), 
                       update_freq=&#39;epoch&#39;, 
                       histogram_freq=self.config.get_parameter(&#34;histogram_freq&#34;))</code></pre>
</details>
</dd>
<dt id="models.CNN_Base.CNN_Base.train_model"><code class="name flex">
<span>def <span class="ident">train_model</span></span>(<span>self, verbose=True)</span>
</code></dt>
<dd>
<section class="desc"><p>Trains model</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>verbose</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>[Default: True] Verbose output</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train_model(self, verbose = True):
    &#34;&#34;&#34;Trains model
    
    Parameters
    ----------
    verbose : `int`, optional
        [Default: True] Verbose output
    &#34;&#34;&#34;      
    history = self.model.fit(self.aug_images, self.aug_ground_truth, validation_split = self.config.get_parameter(&#34;val_split&#34;),
                             batch_size = self.config.get_parameter(&#34;batch_size&#34;), epochs = self.config.get_parameter(&#34;num_epochs&#34;), shuffle = True,
                             callbacks=self.callbacks, verbose=verbose)
    
    self.end_training()</code></pre>
</details>
</dd>
<dt id="models.CNN_Base.CNN_Base.write_logs"><code class="name flex">
<span>def <span class="ident">write_logs</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Writes the log file</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_logs(self):
    &#34;&#34;&#34;Writes the log file
    &#34;&#34;&#34;
    # Create log_dir if it does not exist
    if os.path.exists(self.log_dir) is False:
        os.makedirs(self.log_dir)
        
    # save the parameters used in current run to logs dir
    self.config.write_config(os.path.join(self.log_dir, &#34;{}-{:%Y%m%dT%H%M}-config.yml&#34;.format(self.config.get_parameter(&#34;name&#34;), self.config.get_parameter(&#34;now&#34;))))</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="models.internals.dataset.Dataset" href="internals/dataset.html#models.internals.dataset.Dataset">Dataset</a></b></code>:
<ul class="hlist">
<li><code><a title="models.internals.dataset.Dataset.augment_images" href="internals/dataset.html#models.internals.dataset.Dataset.augment_images">augment_images</a></code></li>
<li><code><a title="models.internals.dataset.Dataset.augmentations" href="internals/dataset.html#models.internals.dataset.Dataset.augmentations">augmentations</a></code></li>
<li><code><a title="models.internals.dataset.Dataset.get_class_id" href="internals/dataset.html#models.internals.dataset.Dataset.get_class_id">get_class_id</a></code></li>
<li><code><a title="models.internals.dataset.Dataset.list_images" href="internals/image_functions.html#models.internals.image_functions.Image_Functions.list_images">list_images</a></code></li>
<li><code><a title="models.internals.dataset.Dataset.load_dataset" href="internals/dataset.html#models.internals.dataset.Dataset.load_dataset">load_dataset</a></code></li>
<li><code><a title="models.internals.dataset.Dataset.load_ground_truth" href="internals/image_functions.html#models.internals.image_functions.Image_Functions.load_ground_truth">load_ground_truth</a></code></li>
<li><code><a title="models.internals.dataset.Dataset.load_image" href="internals/image_functions.html#models.internals.image_functions.Image_Functions.load_image">load_image</a></code></li>
<li><code><a title="models.internals.dataset.Dataset.pad_image" href="internals/image_functions.html#models.internals.image_functions.Image_Functions.pad_image">pad_image</a></code></li>
<li><code><a title="models.internals.dataset.Dataset.percentile_normalization" href="internals/image_functions.html#models.internals.image_functions.Image_Functions.percentile_normalization">percentile_normalization</a></code></li>
<li><code><a title="models.internals.dataset.Dataset.remove_pad_image" href="internals/image_functions.html#models.internals.image_functions.Image_Functions.remove_pad_image">remove_pad_image</a></code></li>
<li><code><a title="models.internals.dataset.Dataset.reshape_image" href="internals/image_functions.html#models.internals.image_functions.Image_Functions.reshape_image">reshape_image</a></code></li>
<li><code><a title="models.internals.dataset.Dataset.sanity_check" href="internals/dataset.html#models.internals.dataset.Dataset.sanity_check">sanity_check</a></code></li>
<li><code><a title="models.internals.dataset.Dataset.tile_image" href="internals/image_functions.html#models.internals.image_functions.Image_Functions.tile_image">tile_image</a></code></li>
<li><code><a title="models.internals.dataset.Dataset.untile_image" href="internals/image_functions.html#models.internals.image_functions.Image_Functions.untile_image">untile_image</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="models" href="index.html">models</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="models.CNN_Base.CNN_Base" href="#models.CNN_Base.CNN_Base">CNN_Base</a></code></h4>
<ul class="">
<li><code><a title="models.CNN_Base.CNN_Base.compile_model" href="#models.CNN_Base.CNN_Base.compile_model">compile_model</a></code></li>
<li><code><a title="models.CNN_Base.CNN_Base.end_training" href="#models.CNN_Base.CNN_Base.end_training">end_training</a></code></li>
<li><code><a title="models.CNN_Base.CNN_Base.init_logs" href="#models.CNN_Base.CNN_Base.init_logs">init_logs</a></code></li>
<li><code><a title="models.CNN_Base.CNN_Base.initialize_cpu" href="#models.CNN_Base.CNN_Base.initialize_cpu">initialize_cpu</a></code></li>
<li><code><a title="models.CNN_Base.CNN_Base.initialize_gpu" href="#models.CNN_Base.CNN_Base.initialize_gpu">initialize_gpu</a></code></li>
<li><code><a title="models.CNN_Base.CNN_Base.initialize_model" href="#models.CNN_Base.CNN_Base.initialize_model">initialize_model</a></code></li>
<li><code><a title="models.CNN_Base.CNN_Base.initialize_model_normal" href="#models.CNN_Base.CNN_Base.initialize_model_normal">initialize_model_normal</a></code></li>
<li><code><a title="models.CNN_Base.CNN_Base.load_model" href="#models.CNN_Base.CNN_Base.load_model">load_model</a></code></li>
<li><code><a title="models.CNN_Base.CNN_Base.load_weights" href="#models.CNN_Base.CNN_Base.load_weights">load_weights</a></code></li>
<li><code><a title="models.CNN_Base.CNN_Base.loss_function" href="#models.CNN_Base.CNN_Base.loss_function">loss_function</a></code></li>
<li><code><a title="models.CNN_Base.CNN_Base.model_checkpoint_call" href="#models.CNN_Base.CNN_Base.model_checkpoint_call">model_checkpoint_call</a></code></li>
<li><code><a title="models.CNN_Base.CNN_Base.optimizer_function" href="#models.CNN_Base.CNN_Base.optimizer_function">optimizer_function</a></code></li>
<li><code><a title="models.CNN_Base.CNN_Base.predict_images" href="#models.CNN_Base.CNN_Base.predict_images">predict_images</a></code></li>
<li><code><a title="models.CNN_Base.CNN_Base.save_image" href="#models.CNN_Base.CNN_Base.save_image">save_image</a></code></li>
<li><code><a title="models.CNN_Base.CNN_Base.summary" href="#models.CNN_Base.CNN_Base.summary">summary</a></code></li>
<li><code><a title="models.CNN_Base.CNN_Base.tensorboard_call" href="#models.CNN_Base.CNN_Base.tensorboard_call">tensorboard_call</a></code></li>
<li><code><a title="models.CNN_Base.CNN_Base.train_model" href="#models.CNN_Base.CNN_Base.train_model">train_model</a></code></li>
<li><code><a title="models.CNN_Base.CNN_Base.write_logs" href="#models.CNN_Base.CNN_Base.write_logs">write_logs</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.1</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>